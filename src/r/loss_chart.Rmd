---
title: "Loss Charts"
author: "Jonathan Dayton"
date: "12/27/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load("tidyverse", "gridExtra", "png", "stringr", "magick", "colorspace", "pracma")
```

# Load data

```{r}
training_log_files <- dir("../../data/metrics/training/", pattern = ".*\\.csv", full.names = TRUE)
log_dfs <- do.call("rbind", lapply(training_log_files, read_csv))
```

# Look at the data

## Number of autoencoder layers doesn't seem to matter after 1

```{r}
final_iter <- log_dfs %>% group_by(start_time) %>% summarize(iteration = max(iteration)) %>% left_join(log_dfs)
final_iter %>% filter(str_detect(output_path, "ae_layers_")) %>%
  ggplot(aes(x = autoencoder_layers, y = dual_loss)) +
  geom_line() +
  labs(x = "Number of Autoencoder Layers", y = "Dual Loss Value")
```

## More layers in the discriminator generally means lower final loss

```{r}
final_iter %>% filter(str_detect(output_path, "/layers_")) %>%
  filter(discriminator_layers > 0) %>%
  ggplot(aes(x = discriminator_layers, y = dual_loss)) +
  geom_line() +
  labs(x = "Number of Discriminator Layers", y = "Dual Loss Value")
```

## The optimal code size seems to be between 1000 and 10,000

```{r}
final_iter %>% filter(str_detect(output_path, "/code_size")) %>%
  filter(discriminator_layers > 0) %>%
  ggplot(aes(x = code_size, y = dual_loss)) +
  geom_point() +
  geom_smooth() +
  labs(x = "Nodes in Code Layer", y = "Dual Loss Value") +
  scale_x_log10()
```

```{r}
final_iter %>% filter(str_detect(output_path, "/scaling")) %>%
  ggplot(aes(x = scaling_method, y = dual_loss)) +
  geom_bar(stat = "identity") +
  labs(x = "Scaling Method", y = "Dual Loss Value")
```

[1] "../../data/metrics/training//ae_layers.csv"   "../../data/metrics/training//code_size.csv"  
[3] "../../data/metrics/training//features.csv"    "../../data/metrics/training//layers.csv"     
[5] "../../data/metrics/training//loss_weight.csv" "../../data/metrics/training//mnist.csv"      
[7] "../../data/metrics/training//scaling.csv"    


```{r}

run <- log_dfs %>% filter(discriminator_layers == 9) 

run %>%
  # filter(iteration > 4000) %>%
  ggplot(aes(x = iteration, y = dual_loss)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Dual Loss", y = "Loss", x = "Iteration")

run %>%
  ggplot(aes(x = iteration, y = ae_loss)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Autoencoder Loss", y = "Loss", x = "Iteration")

run %>%
  ggplot(aes(x = iteration, y = disc_loss)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Discriminator Loss", y = "Loss", x = "Iteration")
```

## MNIST Grid

```{r}
paths <- paste("../../data/output/mnist/", list.files("../../data/output/mnist/", pattern = "\\.png$"), sep="")
pngs <- lapply(paths, readPNG)
gl <- lapply(pngs, grid::rasterGrob)
grid.arrange(grobs=gl, ncol=4)
```

```{r}
dfs <- list(
  Unadjusted = read_csv("../../data/mnist/unadjusted.csv") %>% select(-Batch, -Sample, -Digit),
  `Artificial noise` = read_csv("../../data/mnist/noisy.csv") %>% select(-Batch, -Sample, -Digit),
  Scale = read_csv("../../data/mnist/noisy_scale.csv") %>% select(-Batch, -Sample, -Digit),
  ComBat = read_csv("../../data/mnist/noisy_combat.csv") %>% select(-Batch, -Sample, -Digit),
  Confounded = read_csv("../../data/mnist/noisy_confounded.csv") %>% select(-Batch, -Sample, -Digit)
)
```

```{r}
set.seed(0)
pic_rows <- sort(sample.int(nrow(unadj), 5))

image_from_vector <- function(x) {
  return(image_read(aperm(array(as.numeric(x), c(28, 28, 1)), c(2, 1, 3))))
}

big_img <- NULL
imgs <- list()
for (name in names(dfs)) {
  img <- NULL
  df <- dfs[[name]]
  for (i in pic_rows) {
    new_img <- image_from_vector(df[i,])
    if (is.null(img)) {
      img <- new_img
    } else {
      img <- image_append(c(img, new_img))
    }
  }
  imgs[[i]] <- img
  if (is.null(big_img)) {
    big_img <- img
  } else {
    big_img <- image_append(c(big_img, img), stack = TRUE)
  }
}

label_width <- 65
text_background <- image_scale(image_read(array(rep(1, 28*label_width), c(28, label_width, 1))), "x100")
labels <- NULL
for (name in names(dfs)) {
  new_label <- image_annotate(text_background, name, gravity = "center", size = 32)
  if (is.null(labels)) {
    labels <- new_label
  } else {
    labels <- image_append(c(labels, new_label), stack = TRUE)
  }
}

big_img <- image_scale(big_img, "500")
labelled <- image_append(c(labels, big_img))

image_write(labelled, "../../../../research/thesis/figures/final/mnist.png")
```









